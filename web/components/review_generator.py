import streamlit as st
from src.llm import LLMFactory
from src.synthesis import LiteratureReviewGenerator, CitationManager
from config import settings

def render_review_page():
    st.header("ğŸ“ ç”Ÿæˆæ–‡çŒ®ç»¼è¿°")
    
    topic = st.text_input("ç ”ç©¶ä¸»é¢˜", placeholder="ä¾‹å¦‚: æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨")
    
    col1, col2 = st.columns(2)
    
    with col1:
        n_papers = st.slider("ä½¿ç”¨è®ºæ–‡æ•°é‡", 5, 50, 20)
    
    with col2:
        review_type = st.selectbox("ç»¼è¿°ç±»å‹", ["å®Œæ•´ç»¼è¿°", "ç®€çŸ­æ‘˜è¦"])
    
    if st.button("ğŸš€ ç”Ÿæˆç»¼è¿°", type="primary"):
        if not topic:
            st.warning("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜")
            return
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆç»¼è¿°..."):
            try:
                papers = st.session_state.query_engine.query(
                    topic, method="hybrid", n_results=n_papers
                )
                
                if not papers:
                    st.error("æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                    return
                
                st.info(f"æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")
                
                # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
                provider = st.session_state.llm_provider
                model = st.session_state.llm_model
                base_url = st.session_state.get('llm_base_url')
                api_key = st.session_state.get('llm_api_key')
                
                with st.expander("ğŸ”§ LLMé…ç½®"):
                    st.write(f"Provider: {provider}")
                    st.write(f"Model: {model}")
                    st.write(f"Base URL: {base_url}")
                    st.write(f"Has API Key: {bool(api_key)}")
                
                # éªŒè¯é…ç½®
                if provider == "custom":
                    if not base_url:
                        st.error("âš ï¸ è¯·åœ¨ä¾§è¾¹æ é…ç½®ä¸­è¾“å…¥ API URL")
                        return
                    if not api_key:
                        st.error("âš ï¸ è¯·åœ¨ä¾§è¾¹æ é…ç½®ä¸­è¾“å…¥ API Key")
                        return
                    st.info(f"âœ… ä½¿ç”¨è‡ªå®šä¹‰API: {base_url}")
                
                llm = LLMFactory.create_llm(
                    provider=provider,
                    model=model,
                    api_key=api_key,
                    base_url=base_url
                )
                
                generator = LiteratureReviewGenerator(llm, st.session_state.sql_manager)
                
                if review_type == "ç®€çŸ­æ‘˜è¦":
                    review_text = generator.generate_summary(papers, topic)
                    st.markdown("### æ‘˜è¦")
                    st.markdown(review_text)
                else:
                    review_text = generator.generate_review(papers, topic, max_papers=n_papers)
                    st.markdown(f"# {topic} - æ–‡çŒ®ç»¼è¿°")
                    st.markdown(review_text)
                
                st.markdown("## å‚è€ƒæ–‡çŒ®")
                citation_manager = CitationManager()
                for paper in papers:
                    citation_manager.add_citation(paper)
                
                bibliography = citation_manager.generate_bibliography("apa")
                st.markdown(bibliography)
                
                full_text = f"# {topic}\n\n{review_text}\n\n## å‚è€ƒæ–‡çŒ®\n\n{bibliography}"
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»¼è¿°",
                    data=full_text,
                    file_name=f"{topic}_review.md",
                    mime="text/markdown"
                )
                
                st.success("âœ… ç»¼è¿°ç”Ÿæˆå®Œæˆï¼")
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
                
                # æ£€æŸ¥å¸¸è§é—®é¢˜
                if "Connection" in str(e) or "refused" in str(e):
                    st.error("âš ï¸ Ollamaæœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨: ollama serve")
                elif "model" in str(e).lower():
                    st.error(f"âš ï¸ æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä¸‹è½½: ollama pull {st.session_state.llm_model}")
                
                with st.expander("ğŸ æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                    import traceback
                    st.code(traceback.format_exc())
