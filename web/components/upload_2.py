import streamlit as st
from pathlib import Path
import tempfile
from src.parsers import ParserFactory, TextChunker
from src.llm import LLMFactory
from config import settings

def render_upload_page():
    st.header("ğŸ“¤ ä¸Šä¼ è®ºæ–‡")
    
    st.markdown("""
    ä¸Šä¼ PDFè®ºæ–‡æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è§£æå¹¶åˆ›å»ºç´¢å¼•ã€‚
    
    ğŸ’¡ **æç¤º**: å¦‚æœä½¿ç”¨LLMæå–ï¼Œè¯·ç¡®ä¿ä¾§è¾¹æ ä¸­çš„LLMæœåŠ¡å·²é…ç½®å¹¶è¿è¡Œã€‚
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        parser_type = st.selectbox(
            "é€‰æ‹©è§£æå™¨", 
            ["mineru"],
            help="MinerU: é«˜è´¨é‡GPUåŠ é€Ÿ"
        )
    
    with col2:
        use_llm = st.checkbox("ä½¿ç”¨LLMæå–å…ƒæ•°æ®", value=True, help="æ™ºèƒ½æå–æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ç­‰ï¼ˆéœ€è¦LLMæœåŠ¡è¿è¡Œï¼‰")
    
    use_gpu = False
    if parser_type == "mineru":
        use_gpu = st.checkbox("ä½¿ç”¨GPUåŠ é€Ÿ", value=True, help="éœ€è¦CUDAç¯å¢ƒ")
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=['pdf'],
        accept_multiple_files=True,
        help="æ”¯æŒæ‰¹é‡ä¸Šä¼ ï¼Œå»ºè®®æ¯æ¬¡ä¸è¶…è¿‡10ç¯‡"
    )
    
    if uploaded_files and st.button("å¼€å§‹å¯¼å…¥", type="primary"):
        # åˆå§‹åŒ–LLM

        
        progress_bar = st.progress(0)
        status_text = st.empty()
        success_count = 0
        
        for i, uploaded_file in enumerate(uploaded_files):
            unparsed_path = None
            parsed_path = None
            try:
                status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")
                
                # åˆ›å»ºä¸¤ä¸ªç›®å½•ï¼šæœªè§£æå’Œå·²è§£æ
                unparsed_dir = Path(settings.PDF_DIR) / "unparsed"
                parsed_dir = Path(settings.PDF_DIR) / "parsed"

                unparsed_dir.mkdir(parents=True, exist_ok=True)
                parsed_dir.mkdir(parents=True, exist_ok=True)
                
                
                # å…ˆä¿å­˜åˆ°æœªè§£æç›®å½•
                unparsed_path = unparsed_dir / uploaded_file.name
                
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
                if unparsed_path.exists():
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"{unparsed_path.stem}_{timestamp}.pdf"
                    unparsed_path = unparsed_dir / filename
                else:
                    filename = uploaded_file.name
                
                unparsed_path.write_bytes(uploaded_file.read())
                
        

                # åˆ›å»ºè§£æå™¨ï¼ˆMinerUæ”¯æŒLLMï¼‰
                # if parser_type == "mineru":
                #     from src.parsers.mineru_chunker import MinerUParser
                #     parser = MinerUParser(use_gpu=use_gpu, llm=llm)
                # else:
                #     parser = ParserFactory.create_parser(parser_type, use_gpu=use_gpu)
                
                # è§£æPDFï¼ˆä½¿ç”¨æœªè§£æç›®å½•çš„æ–‡ä»¶ï¼‰
                # parsed = parser.parse(str(unparsed_path))
                
                # è§£ææˆåŠŸåï¼Œç§»åŠ¨åˆ°å·²è§£æç›®å½•
                # parsed_path = parsed_dir / filename
                # unparsed_path.rename(parsed_path)
                
                # å­˜å…¥æ•°æ®åº“ï¼ˆä½¿ç”¨å·²è§£æç›®å½•çš„è·¯å¾„ï¼‰
                # paper_id = st.session_state.sql_manager.add_paper(
                #     title=parsed.title,
                #     pdf_path=str(parsed_path),
                #     authors=', '.join(parsed.authors) if isinstance(parsed.authors, list) else parsed.authors,
                #     raw_text=parsed.full_text,
                #     markdown_text=parsed.markdown_text
                # )
                
                # å‘é‡åŒ–å­˜å‚¨
                # chunker = TextChunker(settings.CHUNK_SIZE, settings.CHUNK_OVERLAP)
                # chunks = chunker.chunk_text(parsed.full_text, {"paper_id": paper_id})
                
                # if chunks:
                #     chunk_texts = [chunk["text"] for chunk in chunks]
                #     st.session_state.vector_manager.add_fulltext(paper_id, chunk_texts)
                
                success_count += 1
                st.success(f"âœ“ {uploaded_file.name}")
                
            except Exception as e:
                error_msg = str(e)
                if "503" in error_msg:
                    st.error(f"å¤„ç† {uploaded_file.name} å¤±è´¥: LLMæœåŠ¡ä¸å¯ç”¨")
                else:
                    st.error(f"å¤„ç† {uploaded_file.name} å¤±è´¥: {error_msg}")
                    # å¦‚æœå¤„ç†å¤±è´¥ï¼ŒPDFä¿ç•™åœ¨unparsedç›®å½•
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        status_text.empty()
        
        if success_count == len(uploaded_files):
            st.success(f"âœ… å…¨éƒ¨å¯¼å…¥æˆåŠŸï¼å…± {success_count} ç¯‡è®ºæ–‡")
            st.balloons()
        elif success_count > 0:
            st.warning(f"âš  éƒ¨åˆ†å¯¼å…¥æˆåŠŸ: {success_count}/{len(uploaded_files)} ç¯‡è®ºæ–‡")
        else:
            st.error("âŒ å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
