import os
import subprocess
import json
from pathlib import Path
import chromadb
from chromadb.utils import embedding_functions

class PaperParserCLI:
    """ä½¿ç”¨ MinerU (GPUåŠ é€Ÿ) è§£æ PDF å¹¶å­˜å‚¨åˆ° ChromaDB"""
    
    _model_singleton = None  # ç±»çº§åˆ«çš„æ¨¡å‹ç¼“å­˜
    
    def __init__(self, chroma_persist_dir="./chroma_db", use_gpu=True):
        """åˆå§‹åŒ–è§£æå™¨å’ŒChromaDBå®¢æˆ·ç«¯"""
        # åˆå§‹åŒ–ChromaDB
        self.client = chromadb.PersistentClient(path=chroma_persist_dir)
        
        # ä½¿ç”¨é»˜è®¤çš„embeddingå‡½æ•°
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()
        
        # åˆ›å»ºæˆ–è·å–collection
        self.collection = self.client.get_or_create_collection(
            name="research_papers",
            embedding_function=self.embedding_fn,
            metadata={"description": "Research papers parsed from PDFs"}
        )
        
        self.use_gpu = use_gpu
        self._check_gpu()
    
    def _check_gpu(self):
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        if self.use_gpu:
            try:
                import torch
                if torch.cuda.is_available():
                    print(f"âœ“ GPU å¯ç”¨: {torch.cuda.get_device_name(0)}")
                else:
                    print("âš  GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU")
                    self.use_gpu = False
            except ImportError:
                print("âš  PyTorch æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ CPU")
                self.use_gpu = False
    
    def parse_pdf_with_mineru(self, pdf_path, output_dir="./output"):
        """ä½¿ç”¨ MinerU å‘½ä»¤è¡Œå·¥å…·è§£æ PDF (æ”¯æŒGPUåŠ é€Ÿ)"""
        pdf_path = Path(pdf_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True, parents=True)
        
        print(f"{'ğŸš€ GPU' if self.use_gpu else 'ğŸ¢ CPU'} åŠ é€Ÿè§£æ")
        
        # ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆæ›´ç¨³å®šï¼‰
        cmd = [
            "mineru",
            "-p", str(pdf_path),
            "-o", str(output_dir)
        ]
        
        if self.use_gpu:
            cmd.extend(["--device", "cuda"])
        
        print(f"ğŸ“„ æ­£åœ¨è§£æ: {pdf_path.name}")
        print(f"æ‰§è¡Œ: {' '.join(cmd)}")
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âš  å‘½ä»¤è¡Œå¤±è´¥ï¼Œå°è¯• PyMuPDF å¿«é€Ÿè§£æ...")
            return self._parse_with_pymupdf(pdf_path, output_dir)
        
        # è¯»å–ç”Ÿæˆçš„Markdown
        return self._read_markdown_output(pdf_path, output_dir)
    
    def _parse_with_pymupdf(self, pdf_path, output_dir):
        """å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ PyMuPDF å¿«é€Ÿè§£æ"""
        try:
            import fitz
        except ImportError:
            raise ImportError("è¯·å®‰è£…: pip install PyMuPDF")
        
        doc = fitz.open(pdf_path)
        md_content = ""
        
        for page in doc:
            md_content += page.get_text()
        
        doc.close()
        
        # ä¿å­˜
        md_path = output_dir / f"{pdf_path.stem}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"âœ“ è§£æå®Œæˆ (PyMuPDF): {md_path}")
        return md_content, str(output_dir)
    
    def _read_markdown_output(self, pdf_path, output_dir):
        """è¯»å–ç”Ÿæˆçš„ Markdown æ–‡ä»¶"""
        pdf_name = pdf_path.stem
        
        # å°è¯•ä¸åŒçš„å¯èƒ½è·¯å¾„
        possible_paths = [
            output_dir / pdf_name / "auto" / f"{pdf_name}.md",
            output_dir / pdf_name / f"{pdf_name}.md",
            output_dir / f"{pdf_name}.md",
        ]
        
        for md_path in possible_paths:
            if md_path.exists():
                print(f"æ‰¾åˆ° Markdown æ–‡ä»¶: {md_path}")
                with open(md_path, 'r', encoding='utf-8') as f:
                    return f.read(), str(md_path.parent)
        
        raise FileNotFoundError(
            f"æ— æ³•æ‰¾åˆ°ç”Ÿæˆçš„ Markdown æ–‡ä»¶ã€‚æ£€æŸ¥äº†ä»¥ä¸‹è·¯å¾„:\n" + 
            "\n".join(str(p) for p in possible_paths)
        )
    
    def chunk_text(self, text, chunk_size=1000, overlap=200):
        """å°†æ–‡æœ¬åˆ†å—ï¼Œæ”¯æŒé‡å """
        chunks = []
        start = 0
        text_length = len(text)
        
        while start < text_length:
            end = start + chunk_size
            chunk = text[start:end]
            
            # å°è¯•åœ¨å¥å­è¾¹ç•Œå¤„åˆ†å‰²
            if end < text_length:
                # å°è¯•å¤šç§åˆ†éš”ç¬¦
                for separator in ['ã€‚\n', 'ã€‚', '\n\n', '\n', '. ', '.']:
                    last_sep = chunk.rfind(separator)
                    if last_sep > chunk_size * 0.5:
                        chunk = chunk[:last_sep + len(separator)]
                        end = start + last_sep + len(separator)
                        break
            
            if chunk.strip():
                chunks.append(chunk.strip())
            
            start = end - overlap
        
        return chunks
    
    def store_to_chromadb(self, pdf_path, chunks):
        """å°†åˆ†å—åçš„å†…å®¹å­˜å‚¨åˆ°ChromaDB"""
        pdf_name = Path(pdf_path).stem
        
        # å‡†å¤‡æ–‡æ¡£ã€IDå’Œå…ƒæ•°æ®
        documents = chunks
        ids = [f"{pdf_name}_chunk_{i}" for i in range(len(chunks))]
        metadatas = [
            {
                "source": pdf_name,
                "chunk_index": i,
                "total_chunks": len(chunks),
                "file_path": str(pdf_path)
            }
            for i in range(len(chunks))
        ]
        
        # æ·»åŠ åˆ°ChromaDB
        self.collection.add(
            documents=documents,
            ids=ids,
            metadatas=metadatas
        )
        
        print(f"âœ“ æˆåŠŸå­˜å‚¨ {len(chunks)} ä¸ªæ–‡æœ¬å—åˆ° ChromaDB")
    
    def process_paper(self, pdf_path, chunk_size=1000, overlap=200):
        """å®Œæ•´å¤„ç†æµç¨‹ï¼šè§£æPDF -> åˆ†å— -> å­˜å‚¨"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç†è®ºæ–‡: {pdf_path}")
        print(f"{'='*60}\n")
        
        # 1. è§£æPDF
        print("ğŸ“„ [1/3] è§£æ PDF...")
        md_content, output_dir = self.parse_pdf_with_mineru(pdf_path)
        print(f"âœ“ è§£æå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(md_content)} å­—ç¬¦")
        
        # 2. åˆ†å—
        print(f"\nğŸ“‘ [2/3] åˆ†å—æ–‡æœ¬ (chunk_size={chunk_size}, overlap={overlap})...")
        chunks = self.chunk_text(md_content, chunk_size, overlap)
        print(f"âœ“ åˆ†å—å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")
        
        # 3. å­˜å‚¨åˆ°ChromaDB
        print(f"\nğŸ’¾ [3/3] å­˜å‚¨åˆ° ChromaDB...")
        self.store_to_chromadb(pdf_path, chunks)
        
        print(f"\n{'='*60}")
        print("âœ“ å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}\n")
        
        return {
            "pdf_path": pdf_path,
            "output_dir": output_dir,
            "chunks_count": len(chunks),
            "md_length": len(md_content)
        }
    
    def query(self, query_text, n_results=5):
        """æŸ¥è¯¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"""
        results = self.collection.query(
            query_texts=[query_text],
            n_results=n_results
        )
        return results
    
    def get_paper_chunks(self, paper_name):
        """è·å–ç‰¹å®šè®ºæ–‡çš„æ‰€æœ‰å—"""
        results = self.collection.get(
            where={"source": paper_name}
        )
        return results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–è§£æå™¨
    parser = PaperParserCLI(chroma_persist_dir="./paper_db")
    
    # å¤„ç†å•ä¸ªPDF
    pdf_file = "data/pdfs/b.pdf"  # æ›¿æ¢ä¸ºä½ çš„PDFè·¯å¾„
    
    if os.path.exists(pdf_file):
        # å¤„ç†è®ºæ–‡
        result = parser.process_paper(
            pdf_file,
            chunk_size=1000,  # æ¯å—å­—ç¬¦æ•°
            overlap=200       # å—ä¹‹é—´çš„é‡å 
        )
        
        print("\nğŸ“Š å¤„ç†ç»“æœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # æŸ¥è¯¢ç¤ºä¾‹
        print("\nğŸ” æŸ¥è¯¢ç¤ºä¾‹:")
        query_result = parser.query("æ·±åº¦å­¦ä¹ ", n_results=3)
        for i, doc in enumerate(query_result['documents'][0]):
            print(f"\n--- ç»“æœ {i+1} ---")
            print(doc[:200] + "...")
    else:
        print(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
        print("è¯·å°† 'your_paper.pdf' æ›¿æ¢ä¸ºå®é™…çš„PDFæ–‡ä»¶è·¯å¾„")